{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the frequency and cause of contradicting highscores\n",
    "**Contributors:** Victor Lin\n",
    "\n",
    "**Achievement:** The frequency of duplicate scores (scores from the same player, beatmap, and mods) was found to be 778, or ~.00078% of the 10M scores present across all dumps. Duplicates can be safely ignored for the data cleaning process.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. *exploration/sql_migration/random_dump_migration.ipynb*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Similar to the exploration of user crossover between random dumps, this notebook takes a closer look at contradicting user highscores, for the same beatmap and dump, found in *random_dump_migration.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from exploration.config import sql_inst, mongo_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osu_random_db = mongo_inst['osu_random_db']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contradicting Highscores Pipeline Filter\n",
    "Define a pipeline that groups highscores by identical (user_id, beatmap_id, and mods) index. Filter for groups with more than one highscore found (aka, contradicting highscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': {\n",
    "                'user_id': '$user_id',\n",
    "                'beatmap_id': '$beatmap_id',\n",
    "                'enabled_mods': '$enabled_mods'\n",
    "            },\n",
    "            'count': {\n",
    "                \n",
    "                '$sum': 1\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$match': {\n",
    "            'count': {\n",
    "                '$gt': 1\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "duplicate_indecies = osu_random_db['osu_scores_high'].aggregate(pipeline, allowDiskUse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying highscores from each multi-index\n",
    "For the Aug - Jan dumps, it appears there are only cases of 2 contradicting highscores for each index (as opposed to 3 or more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_highscores = []\n",
    "\n",
    "for duplicate_index in duplicate_indecies:\n",
    "    index = duplicate_index['_id']\n",
    "    duplicate_highscores.extend(osu_random_db['osu_scores_high'].find(index, {'mlpp': 0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Highscores with DataFrame\n",
    "Reordered table columns to have the 3 indexed columsn (beatmap_id, user_id, enabled_mods) to be first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(duplicate_highscores)\n",
    "df.set_index(['beatmap_id', 'user_id', 'enabled_mods'])\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[1:3] + cols[-6:-5] + cols[:1] + cols[3: -6] + cols[-5:]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables for first 5 contradicting pairs of highscores\n",
    "It appears that for each pair, one highscore was submitted in 2011 or 2012 and one in 2017. Perhaps there was a change to score storage in this time that occasionally missed duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'\\n\\nContradicting highscores GROUP {i + 1}')\n",
    "    display(df[2 * i: 2 * (i + 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables for last 5 contradicting pairs of highscores\n",
    "The score _ids for the first 4 pairs are extremely close, and in the 3rd and 4th pair the other columns are the exact same. This may be an unintentional double submission on the serverside. Overall, contradicting highscores appear to be due to server-side errors, and we should simply choose the higher score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(duplicate_indecies)\n",
    "for i in range(N - 5, N):\n",
    "    print(f'\\n\\nContradicting highscores GROUP {i + 1}')\n",
    "    display(df[2 * i: 2 * (i + 1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
