{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the frequency of duplicate scores across several osu random dump\n",
    "**Contributors:** Victor Lin\n",
    "\n",
    "**Achievement:** The frequency of duplicate scores (scores from the same player, beatmap, and mods) was found to be 778, or ~.00078% of the 10M scores present across all dumps. Duplicates can be safely ignored for the data cleaning process.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. env must be set with MySQL DB & Mongo log-in info\n",
    "2. MySQL DB has imported osu standard dumps (random or top) from https://data.ppy.sh/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Isolated osu random dumps contain 10k unique players. However, there can be player crossover *between* dumps. This leads to the possibility of duplicate scores, where a player in an older dump updates their score for a particular beatmap+mod, resulting in a repeat in the new dump.\n",
    "\n",
    "The SQL pipeline to pinpoint the frequency of these duplicates falls under 2 steps:\n",
    "\n",
    "1. Reduce Player Search Space\n",
    "\n",
    "2. Calculate Duplicate Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from exploration.config import sql_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dump_titles = [\n",
    "    \"osu_random_2020_08\",\n",
    "    \"osu_random_2020_09\",\n",
    "    \"osu_random_2020_10\",\n",
    "    \"osu_random_2020_11\",\n",
    "    \"osu_random_2020_12\",\n",
    "    \"osu_random_2021_01\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reduce Search Space\n",
    "Union all osu_user_stats tables to identify only the players with crossover. No need to search other players, as they cannot have duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_repeat_users(dump_titles):\n",
    "    template = \"(SELECT user_id FROM {}.osu_user_stats)\".format\n",
    "    QUERY_UNION_USER_ID = '\\nUNION ALL\\n'.join(map(template, random_dump_titles))\n",
    "\n",
    "    with sql_inst.cursor() as cursor:\n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            SELECT user_id\n",
    "            FROM (\n",
    "                {QUERY_UNION_USER_ID}\n",
    "            )as USERS_INCLUDING_DUPE\n",
    "            GROUP BY user_id\n",
    "            HAVING COUNT(*) > 1\n",
    "            ORDER BY COUNT(*) DESC \n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        return tuple(row[0] for row in cursor)\n",
    "\n",
    "REPEAT_USERS_TUPLE = find_repeat_users(random_dump_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Frequency Calculation\n",
    "Only for osu highscores from the players identified, group scores by unique (player, beatmap, mod) combinations. Accumulate the frequency of groups > 1 (aka duplicate scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repeat_freq_table(repeat_users):\n",
    "    template = (\"\"\"\n",
    "    SELECT score_id, user_id, beatmap_id, enabled_mods\n",
    "            FROM {}.osu_scores_high\n",
    "            WHERE\n",
    "            user_id IN \"\"\" + str(REPEAT_USERS_TUPLE)\n",
    "    ).format\n",
    "\n",
    "    QUERY_USERS_UNION_SCORES = '\\nUNION\\n'.join(map(template, random_dump_titles))\n",
    "\n",
    "    query = f\"\"\"\n",
    "            SELECT B.num_dumps, COUNT(*) as freq FROM (\n",
    "                SELECT COUNT(*) as num_dumps FROM (\n",
    "                    {QUERY_USERS_UNION_SCORES}\n",
    "                ) as A\n",
    "                GROUP BY A.user_id, A.beatmap_id, A.enabled_mods\n",
    "            ) as B\n",
    "            WHERE B.num_dumps > 1\n",
    "            GROUP BY B.num_dumps\n",
    "            \"\"\"\n",
    "\n",
    "    return pd.read_sql(query, sql_inst)\n",
    "\n",
    "get_repeat_freq_table(REPEAT_USERS_TUPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "The above table shows score repeats for 2 dumps were found 778 times out of all 6 osu random dumps. There were no scores that were found across 3 or more dumps. This makes sense, as the probability of each additional dump update should exponentially decreases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
